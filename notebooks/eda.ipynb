{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8897493",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import libraries such as pandas, numpy, matplotlib, and seaborn for data analysis and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967beb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.io import arff\n",
    "\n",
    "# Set visualization style\n",
    "sns.set(style=\"whitegrid\")\n",
    "# Increase font size for better readability\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3453b948",
   "metadata": {},
   "source": [
    "# Load Datasets\n",
    "Load both JM1 and KC1 datasets from ARFF files and convert them to pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da28a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Datasets\n",
    "def load_arff_dataset(file_path):\n",
    "    data, meta = arff.loadarff(file_path)\n",
    "    df = pd.DataFrame(data)\n",
    "    # Convert byte strings to regular strings\n",
    "    for col in df.select_dtypes([\"object\"]):\n",
    "        df[col] = df[col].str.decode(\"utf-8\")\n",
    "    return df\n",
    "\n",
    "# Load both datasets\n",
    "jm1_path = \"../data/raw/jm1.arff\"\n",
    "kc1_path = \"../data/raw/kc1.arff\"\n",
    "\n",
    "jm1_df = load_arff_dataset(jm1_path)\n",
    "kc1_df = load_arff_dataset(kc1_path)\n",
    "\n",
    "print(\"JM1 Dataset Shape:\", jm1_df.shape)\n",
    "print(\"KC1 Dataset Shape:\", kc1_df.shape)\n",
    "print(\"\\nJM1 Column Names:\", jm1_df.columns.tolist())\n",
    "print(\"\\nData Types (JM1):\\n\", jm1_df.dtypes)\n",
    "jm1_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edf4bb1",
   "metadata": {},
   "source": [
    "# Analyze Class Distribution\n",
    "Examine the distribution of defects in both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5b0981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Class Distributions for both datasets\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# JM1 distribution\n",
    "jm1_counts = jm1_df['defects'].value_counts()\n",
    "sns.barplot(x=jm1_counts.index, y=jm1_counts.values, ax=ax1)\n",
    "ax1.set_title(\"JM1 Class Distribution\")\n",
    "ax1.set_xlabel(\"Defect Status\")\n",
    "ax1.set_ylabel(\"Count\")\n",
    "\n",
    "# KC1 distribution\n",
    "kc1_counts = kc1_df['defects'].value_counts()\n",
    "sns.barplot(x=kc1_counts.index, y=kc1_counts.values, ax=ax2)\n",
    "ax2.set_title(\"KC1 Class Distribution\")\n",
    "ax2.set_xlabel(\"Defect Status\")\n",
    "ax2.set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print class distribution percentages\n",
    "print(\"JM1 Class Distribution:\")\n",
    "print(jm1_df['defects'].value_counts(normalize=True).round(3) * 100, \"%\\n\")\n",
    "print(\"KC1 Class Distribution:\")\n",
    "print(kc1_df['defects'].value_counts(normalize=True).round(3) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b59d3f6",
   "metadata": {},
   "source": [
    "# Feature Distributions\n",
    "Analyze the distributions of numerical features using histograms and KDE plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775bfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical features (exclude 'defects' column)\n",
    "numerical_features = [col for col in jm1_df.columns if col != 'defects']\n",
    "\n",
    "# Create a function to plot feature distributions\n",
    "def plot_feature_distributions(feature, df1, df2, dataset1_name='JM1', dataset2_name='KC1'):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot for first dataset\n",
    "    sns.histplot(df1[feature], kde=True, bins=30, ax=ax1)\n",
    "    ax1.set_title(f\"{dataset1_name} - {feature}\")\n",
    "    \n",
    "    # Plot for second dataset\n",
    "    sns.histplot(df2[feature], kde=True, bins=30, ax=ax2)\n",
    "    ax2.set_title(f\"{dataset2_name} - {feature}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot distributions for each feature\n",
    "for feature in numerical_features[:5]:  # Start with first 5 features\n",
    "    plot_feature_distributions(feature, jm1_df, kc1_df)\n",
    "    \n",
    "# Print basic statistics\n",
    "print(\"JM1 Dataset Statistics:\")\n",
    "print(jm1_df[numerical_features[:5]].describe())\n",
    "print(\"\\nKC1 Dataset Statistics:\")\n",
    "print(kc1_df[numerical_features[:5]].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7168e92",
   "metadata": {},
   "source": [
    "# Correlation Analysis\n",
    "Generate and compare correlation matrices for both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e891ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create correlation matrix plot\n",
    "def plot_correlation_matrix(df, title):\n",
    "    correlation_matrix = df[numerical_features].corr()\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    mask = np.triu(np.ones_like(correlation_matrix))\n",
    "    sns.heatmap(correlation_matrix, mask=mask, annot=True, fmt='.2f',\n",
    "               cmap='coolwarm', center=0, square=True, cbar_kws={\"shrink\": .5})\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot correlation matrices\n",
    "plot_correlation_matrix(jm1_df, \"JM1 Dataset - Feature Correlations\")\n",
    "plot_correlation_matrix(kc1_df, \"KC1 Dataset - Feature Correlations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c7e433",
   "metadata": {},
   "source": [
    "# Feature Importance Analysis\n",
    "Analyze feature importance using mutual information scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d868d3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "def plot_feature_importance(df, dataset_name):\n",
    "    # Calculate mutual information scores\n",
    "    mi_scores = mutual_info_classif(df[numerical_features], df['defects'])\n",
    "    importance_df = pd.DataFrame({'Feature': numerical_features, 'Importance': mi_scores})\n",
    "    importance_df = importance_df.sort_values('Importance', ascending=True)\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.barplot(data=importance_df, y='Feature', x='Importance')\n",
    "    plt.title(f\"{dataset_name} - Feature Importance (Mutual Information)\")\n",
    "    plt.xlabel(\"Mutual Information Score\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "# Plot feature importance for both datasets\n",
    "jm1_importance = plot_feature_importance(jm1_df, \"JM1\")\n",
    "kc1_importance = plot_feature_importance(kc1_df, \"KC1\")\n",
    "\n",
    "# Print top 5 most important features for each dataset\n",
    "print(\"Top 5 Most Important Features - JM1:\")\n",
    "print(jm1_importance.tail())\n",
    "print(\"\\nTop 5 Most Important Features - KC1:\")\n",
    "print(kc1_importance.tail())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
